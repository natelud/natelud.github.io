---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a Masters student in the [Robotics Institute](https://www.ri.cmu.edu/) at Carnegie Mellon University, where I work with [Professor Katia Sycara](https://www.ri.cmu.edu/ri-faculty/katia-sycara/) in the [Advanced Agent-Robotics Technology (AART) Lab](https://www.ri.cmu.edu/robotics-groups/advanced-agent-robotics-technology-lab/). My current research focuses on developing neuro-symbolic approaches for robot learning and human-robot interaction, with particular emphasis on using knowledge graphs to augmented reinforcement learning in my KG-RL method.

## Research Interests

My work sits at the intersection of machine learning, robotics, and human-robot collaboration. I'm particularly interested in:

- **Physical Human-Robot Interaction:** Safe and natural interaction between physical embodied systems and humans
- **Multi-agent Systems:** Effective coordination between robots and humans in shared tasks
- **Assistive Robotics:** Robots that help people in everyday life
- **Safety-critical Control:** Guaranteeing safe behavior in uncertain, dynamic environments with humans
- **Learning from Demonstrations:** Using human demonstrations to train robots to behave more optimally and interpretably
- **Neuro-symbolic AI:** Combining learning with structured knowledge for robustness and interpretability

## Background

Before joining CMU, I completed my undergraduate degree in Mechanical Engineering at Brigham Young University, where I spent three years in the [RAD Lab](http://radlab.byu.edu/) under [Professor Marc Killpack](https://www.me.byu.edu/directory/marc-killpack) working on dynamic human-robot co-manipulation and control systems. My research focused on developing control algorithms for robots that can safely share physical workspaces with humans, enabling cooperative manipulation of large objects.

During my senior year of undergraduate, I led a capstone research team in the BYU Crop Biomechanics Laboratory under Dr. Douglas Cook, where we developed an automated robotic system for measuring maize stalk stiffness for agricultural phenotyping. I designed a novel strain gauge sensor package and data processing algorithms to convert strain measurements into stiffness metrics, and implemented autonomous navigation and data collection control algorithms for the robotic platform. This work resulted in a publication in MDPI Sensors 2025.

I also gained valuable industry experience at Altitude AI, where I designed perception, path planning, and control algorithms for automated meat packing and processing using industrial robotic arms. One of my key contributions was developing a domain-specific programming language that enables large language models to generate executable code for industrial robots from natural language instructions, dramatically accelerating the prototyping of robotic manipulation tasks. Another key contribution was full stack development of a pork skinning robotic system, including image segmentation, planning, and control algorithms to autonomously cut skin patches from pork bellies using industrial robot arms.

During my time at CMU, I completed a [Robotics Institute Summer Scholars (RISS)](https://riss.ri.cmu.edu/student/nathan-ludlow/) Fellowship working with [Professor John Dolan](https://www.ri.cmu.edu/ri-faculty/john-m-dolan/) in the DRIVE Lab on human driver modeling for autonomous vehicles. This fellowship project resulted in a first-author publication at ICRA 2024, where I developed a hierarchical learned risk-aware planning framework for simulating human driving behavior. After completing this project, I assisted in the development of Control Barrier Function-inspired Voronoi cell navigation techniques that enable large numbers of agents in multi-agent systems to quickly compute safe controls.

## Current Work

I'm currently developing knowledge graph methods augmented for reinforcement learning (KG-RL) with applications to collaborative robotics scenarios like the Overcooked-AI environment. This work builds on my research in neuro-symbolic AI and aims to enable robots to better understand and predict human behaviors in shared task environments. This project is a collaboration with the Honda Research Institute.

---

*I'm actively preparing PhD applications for Fall 2026, with a focus on human-robot interaction research.*
